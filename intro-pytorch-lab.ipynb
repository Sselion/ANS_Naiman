{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úvod do PyTorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12., 8.)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(5, 3)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konverze PyTorch --> numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konverze numpy --> PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(x.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3)\n",
    "x = Variable(x, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(5, 3)\n",
    "y = Variable(y, requires_grad=False)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x + y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 2 * z * z\n",
    "q = w.mean()\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatický výpočet gradientů"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Načtení dat\n",
    "\n",
    "PyTorch integruje nejpopulárnější testovací datasety přímo ve svém API. CIFAR-10 je jedním z nich. Načtení dat je tak velmi jednoduché:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True)\n",
    "\n",
    "X_train = trainset.train_data\n",
    "y_train = np.array(trainset.train_labels, dtype=np.int64)\n",
    "X_test = testset.test_data\n",
    "y_test = np.array(testset.test_labels, dtype=np.int64)\n",
    "\n",
    "print(type(X_train), X_train.shape, X_train.dtype)\n",
    "print(type(y_train), y_train.shape, y_train.dtype)\n",
    "print(type(X_test), X_test.shape, X_test.dtype)\n",
    "print(type(y_test), y_test.shape, y_test.dtype)\n",
    "\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_train, num_test = X_train.shape[0], X_train.shape[0]\n",
    "x_dim = X_train.shape[1] * X_train.shape[2] * X_train.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cls in enumerate(classes):\n",
    "    cls_ids, = np.where(y_train == i)\n",
    "    draw_ids = np.random.choice(cls_ids, size=10)\n",
    "    \n",
    "    for j, k in enumerate(draw_ids):\n",
    "        plt.subplot(10, 10, j * 10 + i + 1)\n",
    "        plt.imshow(X_train[k])\n",
    "        plt.axis('off')\n",
    "        if j == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(rgb_batch, resize=None):\n",
    "    if isinstance(resize, tuple):\n",
    "        rgb_batch = [cv2.resize(rgb, (32, 32)) for rgb in rgb_batch]\n",
    "    X = np.array(rgb_batch, dtype=np.float32) / 255.\n",
    "    m = np.mean(X, axis=(1, 2))\n",
    "    X -= m[:, None, None, :]\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikace neuronovými sítěmi v PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch: sekvenční API\n",
    "\n",
    "PyTorch nabízí dva základní způsoby definování modelů: sekvenční a funkcionální."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Základní třídou reprezentující neuronovou síť je `Sequential`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fully_con = nn.Sequential(\n",
    "    nn.Linear(x_dim, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, len(classes)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Linear(x_dim, 200)` znamená, že vrstva bude mít výstup o rozměru 200.\n",
    "\n",
    "Model má následující strukturu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(fully_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch: \"funkcionální\" API\n",
    "\n",
    "Vyzkoušíme si také funkcionální API, které se liší pouze ve způsobu definice modelu. Úplně stejný model lze funkcionálním API vytvořit následovně:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, input_dim=x_dim, output_dim=len(classes)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, 200)\n",
    "        self.r1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(200, output_dim)\n",
    "        \n",
    "        if CUDA:\n",
    "            self.cuda()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.fc1(x)\n",
    "        z = self.r1(z)\n",
    "        z = self.fc2(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fully_con = FullyConnected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fully_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, par in fully_con.named_parameters():\n",
    "    print(name, par.shape, par.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializace\n",
    "\n",
    "Inicializace probíhá při definování vrstvy, v tuto chvíli už mají všechny parametry výchozí hodnoty, zde včetně biasů (dříve jsme je nastavovali na nuly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fully_con.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_con.fc1.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jediná inicializace tedy bude vynulovat pole, které bude ukládat historii hodnot lossu a accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trénování \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kritérium lze v PyTorch definovat velmi jednoduše."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobně jako v Kerasu i v PyTorch lze volit mezi různými metodami optimalizace. Opět prozatím zůstaneme u (Minibatch) Stochastic Gradient Descentu (SGD). Ten je reprezentován třídou `SGD`, která má několik (hyper)parametrů, z nichž nám známá je `lr` (learning rate), neboli velikost kroku. Nejdůležitější je ale zadat první povinný argument, který bude optimizéru říkat, jaké parametry modelu má vlastně updatovat. Zde chceme učit všechny vrstvy modelu, jako seznam tedy zadáme `model.parameters()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(fully_con.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zatímco v Kerasu stačí zavolat `model.fit(X, y)`, ve více low-level zaměřeném PyTorch dá trénovací cyklus trochu více práce. Zde je nutné smyčku volající dopředný a zpětný průchod našeho modelu napsat ručně."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, loss_func, optimizer, X_data, y_data, prep_fn=None, batch_size=20, history_output=None, num_iters=None,\n",
    "          print_every=500, permute=True):\n",
    "    model.train()\n",
    "    \n",
    "    if isinstance(history_output, list):\n",
    "        history_output.append({'loss': [], 'acc': []})\n",
    "        \n",
    "    if permute:\n",
    "        perm = np.random.permutation(X_data.shape[0])\n",
    "    else:\n",
    "        perm = np.arange(X_data.shape[0], dtype=np.int)\n",
    "       \n",
    "    if num_iters is None:\n",
    "        num_iters = int(np.ceil(X_data.shape[0] / batch_size))\n",
    "\n",
    "    for n in range(num_iters):\n",
    "        # stejne jako minule navzorkujeme data\n",
    "        batch_ids = perm[n * batch_size:(n + 1) * batch_size]\n",
    "        x = X_data[batch_ids]\n",
    "        if prep_fn is not None:\n",
    "            x = prep_fn(x)\n",
    "        y = y_data[batch_ids]\n",
    "        \n",
    "        x = Variable(torch.from_numpy(x))\n",
    "        y = Variable(torch.from_numpy(y))\n",
    "        \n",
    "        if CUDA:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        \n",
    "        # dopredny pruchod\n",
    "        score = model(x)\n",
    "        \n",
    "        # loss\n",
    "        loss = loss_func(score, y)\n",
    "        \n",
    "        # zpetny pruchod = vypocet gradientu; pred samotnym vypoctem je nutne manualne\n",
    "        # vynulovat gradienty z predchozi iterace, jinak by se vypoctene gradienty pouze\n",
    "        # pricetly k minulym\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parametru\n",
    "        optimizer.step()\n",
    "        \n",
    "        # spocitat statistiky\n",
    "        _, pred = score.data.max(dim=1)\n",
    "        num_correct = torch.sum(pred == y.data)\n",
    "        acc = num_correct / x.shape[0]\n",
    "        \n",
    "        if isinstance(history_output, list):\n",
    "            history_output[-1]['loss'].append(float(loss))\n",
    "            history_output[-1]['acc'].append(acc)\n",
    "        \n",
    "        # cas od casu vypis, jak se dari\n",
    "        if (n + 1) % print_every == 0:\n",
    "            print('trn {}/{}: loss={:.3f}, acc={:.3f}'.format(n + 1, num_iters, float(loss), acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(fully_con, loss_func, optimizer, X_train, y_train, prep_fn=preprocess, history_output=fc_history, print_every=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(model, X_data, y_data, prep_fn=None, batch_size=20, history_output=None, print_every=100):\n",
    "    model.eval()\n",
    "    \n",
    "    if isinstance(history_output, list):\n",
    "        history_output[-1].update({'val_loss': [], 'val_acc': []})\n",
    "    \n",
    "    num_iters = int(np.ceil(X_data.shape[0] / batch_size))\n",
    "    \n",
    "    for n in range(num_iters):\n",
    "        batch_ids = np.arange(n * batch_size, (n + 1) * batch_size)\n",
    "        x = X_data[batch_ids]\n",
    "        if prep_fn is not None:\n",
    "            x = prep_fn(x)\n",
    "        y = y_data[batch_ids]\n",
    "        \n",
    "        x = Variable(torch.from_numpy(x))\n",
    "        y = Variable(torch.from_numpy(y))\n",
    "        \n",
    "        if CUDA:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        \n",
    "        # dopredny pruchod\n",
    "        score = model(x)\n",
    "        \n",
    "        # loss\n",
    "        loss = loss_func(score, y)\n",
    "        \n",
    "        # spocitat statistiky\n",
    "        _, pred = score.data.max(dim=1)\n",
    "        num_correct = torch.sum(pred == y.data)\n",
    "        acc = num_correct / x.shape[0]\n",
    "        \n",
    "        if isinstance(history_output, list):\n",
    "            history_output[-1]['val_loss'].append(float(loss))\n",
    "            history_output[-1]['val_acc'].append(acc)\n",
    "        \n",
    "        # cas od casu vypis, jak se dari\n",
    "        if (n + 1) % print_every == 0:\n",
    "            print('val {}/{}: loss={:.3f}, acc={:.3f}'.format(n + 1, num_iters, float(loss), acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(fully_con, X_test, y_test, prep_fn=preprocess, history_output=fc_history, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    \n",
    "    plt.figure(figsize=(10, 3))\n",
    "    for mi, metric in enumerate(('loss', 'acc')):\n",
    "        plt.subplot(1, 2, mi + 1)\n",
    "        \n",
    "        last = 0.\n",
    "        trn_data, val_data = [], []\n",
    "        for h in history:\n",
    "            trn_data.append(np.mean(h[metric]))\n",
    "            val_data.append(np.mean(h['val_' + metric]) if h.get('val_' + metric) else last)\n",
    "            last = val_data[-1]\n",
    "        \n",
    "        plt.plot(trn_data)\n",
    "        plt.plot(val_data)\n",
    "        \n",
    "        plt.ylabel(metric)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_history(fc_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vše u sebe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fully_con = FullyConnected()\n",
    "fc_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(fully_con.parameters(), lr=0.005)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(10):\n",
    "    train(fully_con, loss_func, optimizer, X_train, y_train, history_output=fc_history, print_every=500)\n",
    "    validate(fully_con, X_test, y_test, history_output=fc_history, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(fc_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predikce\n",
    "\n",
    "Pokud máme natrénovaný model, můžeme predikovat třídu neznámého obrázku metodou `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://camo.githubusercontent.com/7e8b7ea66e6dbc2fbcd72bc2a105ed464de1b6b1/687474703a2f2f6661726d352e737461746963666c69636b722e636f6d2f343037302f343731373336333934355f623733616664373861392e6a7067'\n",
    "img = PIL.Image.open(requests.get(url, stream=True).raw)\n",
    "rgb_test = np.array(img)\n",
    "\n",
    "plt.imshow(rgb_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_and_show(model, rgb):\n",
    "    x = preprocess([rgb], resize=(32, 32))\n",
    "    x = Variable(torch.from_numpy(x))\n",
    "    if CUDA:\n",
    "        x = x.cuda()\n",
    "    \n",
    "    score = model(x).data.cpu().numpy().ravel()\n",
    "    prob = np.exp(score) / np.sum(np.exp(score))\n",
    "            \n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(rgb)\n",
    "    ids = np.argsort(-score)\n",
    "    for i, ci in enumerate(ids):\n",
    "        plt.gcf().text(1., 0.8 - 0.075 * i, '{}: {:.2f} %'.format(classes[ci], 100. * prob[ci]), fontsize=24)\n",
    "    plt.subplots_adjust()\n",
    "    plt.show()\n",
    "    \n",
    "    return ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(trainset))\n",
    "ci = predict_and_show(fully_con, X_train[idx])\n",
    "if ci == y_train[idx]:\n",
    "    num_correct += 1\n",
    "total += 1\n",
    "print(num_correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_show(fully_con, rgb_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
