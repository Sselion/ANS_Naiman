{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generování textu znakovou RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12., 8.)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V tomto cvičení nebudeme používat GPU, protože budeme zpracovávat znaky po jednom a v takto malých dávkách overhead způsobený neustálými přesuny dat mezi GPU a RAM výpočty pouze zpomalí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Namísto obrazu tentokrát použijeme textová data. Konkrétně se jedná o novinové nadpisy, které se budeme snažit generovat automaticky. Všechna data jsou v jediném souboru, který si stáhněte [odsud](https://1drv.ms/t/s!AotVPA94wWKxoWLULaBqvPXiNS5t) a uložte jako `data/headlines.txt`.\n",
    "\n",
    "Z textu byly odstraneny hacky, carky a vsechny nestandardni znaky. Neni tedy potreba resit kodovani apod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('data/headlines.txt').read()\n",
    "lines = [line for line in data.split('\\n') if line]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ukázka dat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(i, random.choice(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sada znaků = náš slovník:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = list(sorted(set(data)))\n",
    "print(len(chars), chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Následující tabulka (`dict`) nám usnadní převod znaku na index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chr2idx = {c: i for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podíváme se na statistické rozložení prvních znaků ve větách."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = {c: 0 for c in chars}\n",
    "for line in lines:\n",
    "    counts[line[0]] += 1\n",
    "counts = np.array([counts[c] for c in chars], dtype=np.float)\n",
    "p0 = counts / counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "rects = plt.bar(range(len(chars)), 100. * p0)\n",
    "plt.xticks(range(len(chars)), ['{}'.format(repr(c)) for c in chars])\n",
    "for r in rects:\n",
    "    x, w, h = r.get_x(), r.get_width(), r.get_height()\n",
    "    plt.text(x + w / 2., h + 0.1, '{:.1f}'.format(h), ha='center', va='bottom', fontsize=8)\n",
    "plt.ylabel('počet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkce pro zobrazení průběhu lossu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history, avg_range=1):\n",
    "    if avg_range > 1:\n",
    "        y = np.mean(np.reshape(history[:avg_range * (len(history) // avg_range)], (-1, avg_range)), axis=1)\n",
    "    else:\n",
    "        y = history\n",
    "    plt.plot(y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sekvenční data a PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Následující funkce převede řetězec na sekvenci čísel odpovídajících indexům znaků v tabulce. Pokud např. `chars = ['a', 'b', 'c']`, pak řetězec `'acba'` převede na `[0, 2, 1, 0]`. Výsledek vrátí jako PyTorch `Variable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = chr2idx[string[c]]\n",
    "    x = Variable(tensor)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = char_tensor('abca')\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Další funkce bude dělat opak: převede sekvenci indexů na řetězec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_string(indices):\n",
    "    if isinstance(indices, Variable):\n",
    "        indices = indices.data\n",
    "    return ''.join([chars[i] for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_string(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekvenci čísel potřebujeme převést na vektory jednotlivých znaků. Tento proces se v anglické literatuře označuje jako embedding a PyTorch ho implementuje jako vrstvu třídou `Embedding`. Vyjádřením této operace diferencovatelnou vrstvou umožňuje učení vektorů, které tedy nemusejí být fixní. O tom ale až příště."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# velikost slovniku je `len(chars)`\n",
    "# dimenze znakoveho vektoru bude napr. 30\n",
    "emb = nn.Embedding(len(chars), 30)\n",
    "\n",
    "# dopredny pruchod\n",
    "e = emb(x)\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch implementuje tři z nejrozšířenějších typů sítí třídami `RNN`, `LSTM` a `GRU`. API je pro všechny stejné: dopředný průchod `forward` očekává \"zespodu\" nějaký vstup `input` a \"zleva\" minulý stav `h0`. U `LSTM` je tento stav dvouvektorový. Výstupem je `output`, což je vlastně sekvence skrytých stavů poslední vrstvy rekurentní sítě pro jednotlivé kroky v čase, a nový stav `hn` po provedení celého průchodu. Vše vystihuje následující obrázek.\n",
    "\n",
    "![](https://i.stack.imgur.com/SjnTl.png)\n",
    "\n",
    "Zdroj: https://stackoverflow.com/a/48305882/9418551\n",
    "\n",
    "V nejjednoušším případě máme pouze jednu vrstvu sítě a jeden krok. Potom `output` a `hn` jsou stejné. `output` tedy **neprochází žádnou lineární vrstvou**, jak by se mohlo na první pohled zdát. Transformaci na skóre/pravděpodobnost jednotlivých znaků tedy musíme provést sami.\n",
    "\n",
    "**Příklad:** porovnejme `output` a `hidden`.\n",
    "tensory by měly být tvaru `(seq, batch, dim)`\n",
    "- `seq` ... jak jdou znaky ve \"věte\" za sebou\n",
    "- `batch` ... počet paralelně zpracovávaných sekvencí, nezávisle na sobě\n",
    "- `dim` ... příznaky na vstupu\n",
    "\n",
    "Například tedy: `(10, 3, 5)` by znamenalo:\n",
    "- 3 paralelně zpracovávané\n",
    "- 10-znakové věty,\n",
    "- kde každý znak reprezentuje 5dimenzionální vektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do site posleme pouze jeden znak\n",
    "e0 = e[0].view(1, 1, -1)\n",
    "e0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RNN ocekava na vstupu vektor o rozmeru 6 a skryty stav bude mit rozmer 8\n",
    "rnn = nn.RNN(30, 8)\n",
    "\n",
    "# inicializace skryteho stavu a vstupu\n",
    "# tensory by mely byt tvaru (seq, batch, dim)\n",
    "h = Variable(torch.rand(8))\n",
    "o, h = rnn(e0)\n",
    "\n",
    "print(o)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní už více samostatně. Zadefinujeme vlastní třídu, která bude řešit jednotlivé kroky sama ve svém dopředném průchodu. Vstupem tedy bude sekvence čísel, výstupem skóre jednotlivých kroků a skrytý stav z posledního kroku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, voc_size, emb_dim, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.emb = ...\n",
    "        self.rnn = ...\n",
    "        self.fc = ...\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        ...\n",
    "        return score, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        h = Variable(torch.zeros(self.rnn.num_layers, 1, self.rnn.hidden_size))\n",
    "        c = Variable(torch.zeros(self.rnn.num_layers, 1, self.rnn.hidden_size))\n",
    "        \n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voc_size = ...\n",
    "emb_dim = ...\n",
    "hidden_dim = ...\n",
    "output_dim = ...\n",
    "\n",
    "rnn = RNN(voc_size, emb_dim, hidden_dim, output_dim, n_layers=1)\n",
    "rnn_history = []\n",
    "example_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vytvoříme trénovací data. `y_train` je v tomto případě stejného rozměru jako `X_train` a ke každému znaku udává následjící. Poslední znak má jako label `\\n`, značící konec sekvence. Data vytvoříme jako seznamy, tj. `list`, kde každý prvek je jedna věta, už převedená na indexy znaků metodou `char_tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = ...\n",
    "y_train = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = random.randrange(len(X_train))\n",
    "print(to_string(X_train[idx].data))\n",
    "print('data:  {} ... {}'.format(to_string(X_train[idx].data.numpy()[:10]), to_string(X_train[idx].data.numpy()[-10:])))\n",
    "print('label: {} ... {}'.format(to_string(y_train[idx].data.numpy()[:10]), to_string(y_train[idx].data.numpy()[-10:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vytvoříme si také funkci pro samplování z naší sítě. Funkce přijme náš model `rnn`, nějaký inicializační text `init_text`, příp. i inicializační `hidden`, a vygeneruje text - vrací tedy string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(rnn, init_text='', hidden=None, maxlen=150, mode='multinomial'):\n",
    "    # vystupni text bude pole (na konci prevedeme na str)\n",
    "    out_text = list(init_text)\n",
    "    \n",
    "    # pokud nezadan, inicializujeme nahodne, dle rozlozeni prvnich znaku\n",
    "    if not out_text:\n",
    "        s = np.random.choice(len(chars), p=p0)\n",
    "        out_text = [chars[s]]\n",
    "    \n",
    "    # to same hidden\n",
    "    if hidden is None:\n",
    "        hidden = rnn.init_hidden()\n",
    "        \n",
    "        # sit projedeme vstupem, abychom ziskali aktualni hidden stav\n",
    "        x = char_tensor(out_text)\n",
    "        for i in range(len(out_text)):\n",
    "            score, hidden = rnn(x[i], hidden)\n",
    "    \n",
    "    # nasledujici znak je posledni znak prozatimniho vystupu\n",
    "    x = char_tensor(out_text[-1])\n",
    "\n",
    "    while True:\n",
    "        # dopredny pruchod\n",
    "        ...\n",
    "        \n",
    "        # pravdepodobnosti znaku\n",
    "        ...\n",
    "        \n",
    "        # vybrat nasledujici znak --> index do `k`\n",
    "        if mode == 'multinomial':\n",
    "            k = torch.multinomial(score.data.view(-1).div(0.9).exp(), 1)[0]\n",
    "        elif mode == 'argmax':\n",
    "            k = ...\n",
    "        elif mode == 'proportional':\n",
    "            k = ...\n",
    "        \n",
    "        # zastavit, pokud end-token\n",
    "        ...\n",
    "        \n",
    "        # pridat znak\n",
    "        text.append(chars[k])\n",
    "        \n",
    "        # zastavit, pokud text je moc dlouhy\n",
    "        ...\n",
    "        \n",
    "        # novy vstupni znak\n",
    "        ...\n",
    "    \n",
    "    return ''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(sample(rnn, init_text='prezident', mode='multinomial'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trénování"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = sample(rnn, mode='argmax')\n",
    "smooth_loss = -np.log(1. / len(chars))\n",
    "max_per_epoch = 10000\n",
    "\n",
    "for epoch in range(1):\n",
    "    if max_per_epoch < len(lines):\n",
    "        perm = np.random.permutation(len(lines))\n",
    "    else:\n",
    "        perm = np.arange(len(lines))\n",
    "    \n",
    "    pb = tqdm.tqdm_notebook(perm, desc='ep {:03d}'.format(epoch))\n",
    "    \n",
    "    for li in enumerate(pb):\n",
    "        hidden = rnn.init_hidden()\n",
    "        rnn.zero_grad()\n",
    "        loss = 0.\n",
    "    \n",
    "        x = ...\n",
    "        y = ...\n",
    "        \n",
    "        for ic, c in enumerate(line):\n",
    "            # dopredny pruchod\n",
    "            ...\n",
    "            \n",
    "            # loss\n",
    "            ...\n",
    "        \n",
    "        loss /= len(x)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if li % 100 == 0:\n",
    "            example = sample(rnn)\n",
    "            example_history.append(example)\n",
    "        \n",
    "        rnn_history.append(float(loss))\n",
    "        smooth_loss = 0.99 * smooth_loss + 0.01 * float(loss)\n",
    "        pb.set_postfix(loss='{:.3f}'.format(smooth_loss), ex=example[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_history(rnn_history, avg_range=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sample(rnn, init_text='prezident', mode='multinomial'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
